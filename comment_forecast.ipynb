{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vk_api import VkApi\n",
    "import vk_api\n",
    "import vk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from nltk.tokenize.casual import TweetTokenizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–≥–Ω–æ–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ—Å—Ç–æ–≤ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id –≥—Ä—É–ø–ø –≤–∫\n",
    "\n",
    "id_avia = '-39283725'\n",
    "id_moscow = '-137324015'\n",
    "id_nazem = '-212086355'\n",
    "mas_id = [id_avia, id_moscow, id_nazem]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≥—Ä—É–ø–ø –≤–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-39283725 0\n",
      "-39283725 100\n",
      "-39283725 200\n",
      "-39283725 300\n",
      "-137324015 0\n",
      "-137324015 100\n",
      "-137324015 200\n",
      "-137324015 300\n",
      "-212086355 0\n",
      "-212086355 100\n",
      "-212086355 200\n",
      "-212086355 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('C:/Users/Admin/Desktop/token.txt') as f:\n",
    "     token = f.readlines()[0]\n",
    "\n",
    "\n",
    "def main(offset: int, token: str, group_id: str):\n",
    "    vk = vk_api.VkApi(token=token)  # –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ç–æ–∫–µ–Ω (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ)\n",
    "    api = vk.get_api()\n",
    "    posts = api.wall.get(owner_id=group_id, offset=offset, count=100)['items']\n",
    "    posts_strings = [post['text'] for post in posts]\n",
    "    num_like = []\n",
    "    comments_strings = []\n",
    "    for post in posts:\n",
    "        comments = api.wall.getComments(\n",
    "            owner_id=group_id, post_id=post['id'], count=100)['items']\n",
    "        comments_strings.append([comment['text'] for comment in comments])\n",
    "        itemID = post['id']\n",
    "        isLiked = api.likes.getList(\n",
    "            type='post',\n",
    "            owner_id=group_id,\n",
    "            item_id=itemID\n",
    "        )\n",
    "        num_like.append(isLiked['count'])\n",
    "    return posts_strings, comments_strings, num_like\n",
    "\n",
    "\n",
    "combo_list_posts = []\n",
    "combolist_comments = []\n",
    "combolist_like = []\n",
    "\n",
    "for group_id in mas_id:\n",
    "    for i in range(0, 301, 100):\n",
    "        try:\n",
    "            rzd_posts, comments_strings_rzd, rzd_like_count = main(\n",
    "                offset=i, token=token, group_id=group_id)\n",
    "            combo_list_posts.extend(rzd_posts)\n",
    "            combolist_comments.extend(comments_strings_rzd)\n",
    "            combolist_like.extend(rzd_like_count)\n",
    "            print(group_id, i)\n",
    "        except:\n",
    "            print('–ü–æ—Å—Ç–æ–≤ –±–æ–ª—å—à–µ –Ω–µ—Ç –Ω–∞ —Å–º–µ—â–µ–Ω–∏–∏: ', i)\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combolist_comments_count = [len(comments) for comments in combolist_comments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ü–æ—Å—Ç—ã</th>\n",
       "      <th>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ö–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª–µ—Ç–Ω—ã–π –∑–∞–≤–æ–¥ (–≤—Ö–æ–¥–∏—Ç –≤ \"–í–µ—Ä—Ç–æ–ª–µ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è Smartwings —Å—Ç–∞–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–í –Ω–æ–≤–æ–º –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–µ–º —Å–µ–∑–æ–Ω–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª–µ—Ç–æ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–¶–ê–ì–ò —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ö–æ–º–ø–∞–Ω–∏—è \"–¢–ö–ü ‚Äî –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ê–∑–∏—è\" (–¢–ö–ü-–¶–ê), –ø–ª...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>–ö–∞–∫ —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞ –º–µ–Ω—è–ª—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –≤...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>‚ö°Ô∏è –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ–ª–∏ –î–æ–º –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å–æ–≤ ¬´–ú–∏...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>–ë–æ–ª—å—à–µ 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω–æ–≥–æ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>üöå –û–±—ä—è–≤–ª—è–µ–º –∫–æ–Ω–∫—É—Ä—Å –≤ —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–µ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>üçÇ –û—Å–µ–Ω—å ‚Äî —ç—Ç–æ –Ω–µ –ª—É–∂–∏ –∏ –≥—Ä—è–∑—å, –∞ –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  –ü–æ—Å—Ç—ã  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏\n",
       "0     –ö–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª–µ—Ç–Ω—ã–π –∑–∞–≤–æ–¥ (–≤—Ö–æ–¥–∏—Ç –≤ \"–í–µ—Ä—Ç–æ–ª–µ...            1\n",
       "1     –ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è Smartwings —Å—Ç–∞–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–æ...            1\n",
       "2     –í –Ω–æ–≤–æ–º –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–µ–º —Å–µ–∑–æ–Ω–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª–µ—Ç–æ...            0\n",
       "3     –¶–ê–ì–ò —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç...            0\n",
       "4     –ö–æ–º–ø–∞–Ω–∏—è \"–¢–ö–ü ‚Äî –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ê–∑–∏—è\" (–¢–ö–ü-–¶–ê), –ø–ª...            0\n",
       "...                                                 ...          ...\n",
       "1195  –ö–∞–∫ —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞ –º–µ–Ω—è–ª—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –≤...            4\n",
       "1196  ‚ö°Ô∏è –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ–ª–∏ –î–æ–º –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å–æ–≤ ¬´–ú–∏...           12\n",
       "1197  –ë–æ–ª—å—à–µ 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω–æ–≥–æ...            6\n",
       "1198  üöå –û–±—ä—è–≤–ª—è–µ–º –∫–æ–Ω–∫—É—Ä—Å –≤ —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–µ...            7\n",
       "1199  üçÇ –û—Å–µ–Ω—å ‚Äî —ç—Ç–æ –Ω–µ –ª—É–∂–∏ –∏ –≥—Ä—è–∑—å, –∞ –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç...           14\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'–ü–æ—Å—Ç—ã': combo_list_posts,\n",
    "                  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': combolist_comments_count})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "–ü–æ—Å—Ç—ã          0\n",
       "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.648323301805675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23324\\2142041351.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  df = df.astype({'–ü–æ—Å—Ç—ã': np.str})\n"
     ]
    }
   ],
   "source": [
    "df = df.astype({'–ü–æ—Å—Ç—ã': np.str})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ\n",
    "    tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É\n",
    "    clean_text = ' '.join(tokens)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "df['clean_text'] = df['–ü–æ—Å—Ç—ã'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ü–æ—Å—Ç—ã</th>\n",
       "      <th>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ö–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª–µ—Ç–Ω—ã–π –∑–∞–≤–æ–¥ (–≤—Ö–æ–¥–∏—Ç –≤ \"–í–µ—Ä—Ç–æ–ª–µ...</td>\n",
       "      <td>1</td>\n",
       "      <td>–∫–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª—ë—Ç–Ω—ã–π –∑–∞–≤–æ–¥ ( –≤—Ö–æ–¥–∏—Ç—å `` –≤–µ—Ä—Ç–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è Smartwings —Å—Ç–∞–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–æ...</td>\n",
       "      <td>1</td>\n",
       "      <td>–∞–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è smartwings —Å—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–í –Ω–æ–≤–æ–º –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–µ–º —Å–µ–∑–æ–Ω–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª–µ—Ç–æ...</td>\n",
       "      <td>0</td>\n",
       "      <td>–Ω–æ–≤—ã–π –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–∏–π —Å–µ–∑–æ–Ω –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª—ë—Ç `` ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–¶–ê–ì–ò —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç...</td>\n",
       "      <td>0</td>\n",
       "      <td>—Ü–∞–≥–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è —ç–Ω–µ—Ä–≥–µ—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ö–æ–º–ø–∞–Ω–∏—è \"–¢–ö–ü ‚Äî –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ê–∑–∏—è\" (–¢–ö–ü-–¶–ê), –ø–ª...</td>\n",
       "      <td>0</td>\n",
       "      <td>–∫–æ–º–ø–∞–Ω–∏—è `` —Ç–∫–ø ‚Äî —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∞–∑–∏—è '' ( —Ç–∫–ø-—Ü–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>–ö–∞–∫ —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞ –º–µ–Ω—è–ª—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –≤...</td>\n",
       "      <td>4</td>\n",
       "      <td>–Ω–∞—á–∞–ª–æ –≥–æ–¥ –º–µ–Ω—è—Ç—å—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –Ω–æ–≤—ã–π –º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>‚ö°Ô∏è –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ–ª–∏ –î–æ–º –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å–æ–≤ ¬´–ú–∏...</td>\n",
       "      <td>12</td>\n",
       "      <td>‚ö°Ô∏è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –¥–æ–º —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å ¬´ –º–∏—Ç–∏–Ω–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>–ë–æ–ª—å—à–µ 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω–æ–≥–æ...</td>\n",
       "      <td>6</td>\n",
       "      <td>–±–æ–ª—å—à–æ–π 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω—ã–π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>üöå –û–±—ä—è–≤–ª—è–µ–º –∫–æ–Ω–∫—É—Ä—Å –≤ —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–µ...</td>\n",
       "      <td>7</td>\n",
       "      <td>üöå –æ–±—ä—è–≤–ª—è—Ç—å –∫–æ–Ω–∫—É—Ä—Å —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏–µ —Å–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>üçÇ –û—Å–µ–Ω—å ‚Äî —ç—Ç–æ –Ω–µ –ª—É–∂–∏ –∏ –≥—Ä—è–∑—å, –∞ –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç...</td>\n",
       "      <td>14</td>\n",
       "      <td>üçÇ –æ—Å–µ–Ω—å ‚Äî —ç—Ç–æ –ª—É–∂–∞ –≥—Ä—è–∑—å , –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç—å –∑–∞—Å—Ç...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  –ü–æ—Å—Ç—ã  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏  \\\n",
       "0     –ö–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª–µ—Ç–Ω—ã–π –∑–∞–≤–æ–¥ (–≤—Ö–æ–¥–∏—Ç –≤ \"–í–µ—Ä—Ç–æ–ª–µ...            1   \n",
       "1     –ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è Smartwings —Å—Ç–∞–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–æ...            1   \n",
       "2     –í –Ω–æ–≤–æ–º –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–µ–º —Å–µ–∑–æ–Ω–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª–µ—Ç–æ...            0   \n",
       "3     –¶–ê–ì–ò —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —ç–Ω–µ—Ä–≥–µ—Ç...            0   \n",
       "4     –ö–æ–º–ø–∞–Ω–∏—è \"–¢–ö–ü ‚Äî –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ê–∑–∏—è\" (–¢–ö–ü-–¶–ê), –ø–ª...            0   \n",
       "...                                                 ...          ...   \n",
       "1195  –ö–∞–∫ —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞ –º–µ–Ω—è–ª—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –≤...            4   \n",
       "1196  ‚ö°Ô∏è –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ–ª–∏ –î–æ–º –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å–æ–≤ ¬´–ú–∏...           12   \n",
       "1197  –ë–æ–ª—å—à–µ 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω–æ–≥–æ...            6   \n",
       "1198  üöå –û–±—ä—è–≤–ª—è–µ–º –∫–æ–Ω–∫—É—Ä—Å –≤ —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–µ...            7   \n",
       "1199  üçÇ –û—Å–µ–Ω—å ‚Äî —ç—Ç–æ –Ω–µ –ª—É–∂–∏ –∏ –≥—Ä—è–∑—å, –∞ –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç...           14   \n",
       "\n",
       "                                             clean_text  \n",
       "0     –∫–∞–∑–∞–Ω—Å–∫–∏–π –≤–µ—Ä—Ç–æ–ª—ë—Ç–Ω—ã–π –∑–∞–≤–æ–¥ ( –≤—Ö–æ–¥–∏—Ç—å `` –≤–µ—Ä—Ç–æ...  \n",
       "1     –∞–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è smartwings —Å—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—à—Å–∫–∏...  \n",
       "2     –Ω–æ–≤—ã–π –≤–µ—Å–µ–Ω–Ω–µ-–ª–µ—Ç–Ω–∏–π —Å–µ–∑–æ–Ω –≥–µ–æ–≥—Ä–∞—Ñ–∏—è –ø–æ–ª—ë—Ç `` ...  \n",
       "3     —Ü–∞–≥–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è —ç–Ω–µ—Ä–≥–µ—Ç...  \n",
       "4     –∫–æ–º–ø–∞–Ω–∏—è `` —Ç–∫–ø ‚Äî —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∞–∑–∏—è '' ( —Ç–∫–ø-—Ü–∞...  \n",
       "...                                                 ...  \n",
       "1195  –Ω–∞—á–∞–ª–æ –≥–æ–¥ –º–µ–Ω—è—Ç—å—Å—è –Ω–∞–∑–µ–º–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –Ω–æ–≤—ã–π –º...  \n",
       "1196  ‚ö°Ô∏è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –¥–æ–º —ç–ª–µ–∫—Ç—Ä–æ–±—É—Å ¬´ –º–∏—Ç–∏–Ω–æ...  \n",
       "1197  –±–æ–ª—å—à–æ–π 183 –º–ª–Ω –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–µ–º–Ω—ã–π...  \n",
       "1198  üöå –æ–±—ä—è–≤–ª—è—Ç—å –∫–æ–Ω–∫—É—Ä—Å —á–µ—Å—Ç—å 2-–ª–µ—Ç–∏–µ —Å–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–≤...  \n",
       "1199  üçÇ –æ—Å–µ–Ω—å ‚Äî —ç—Ç–æ –ª—É–∂–∞ –≥—Ä—è–∑—å , –ø–æ–≤–æ–¥ –ø–æ–º–µ–Ω—è—Ç—å –∑–∞—Å—Ç...  \n",
       "\n",
       "[1163 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 13ms/step - loss: 90.5238 - mae: 5.6016\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 81.7267 - mae: 5.0074\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 65.4811 - mae: 4.4680\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 50.4297 - mae: 4.2025\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 41.2721 - mae: 3.8314\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 34.1847 - mae: 3.1345\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 28.0557 - mae: 2.6644\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 21.7284 - mae: 2.1619\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 18.1854 - mae: 1.8912\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 14.0082 - mae: 1.5886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1caf1723a60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_data = df['clean_text']\n",
    "labels = df['–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏']\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä—ã\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train).toarray() \n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 34.8395 - mae: 3.1047\n",
      "Test Loss: 34.839534759521484, Test MAE: 3.1047074794769287\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test MAE: {mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
